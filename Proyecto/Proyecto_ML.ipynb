{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Proyecto_ML.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN6FctKbjG/fSpiuyFVMjSE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/casalazara/Machine-Learning-IELE/blob/master/Proyecto/Proyecto_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nWTdLoZWk-1"
      },
      "source": [
        "import os\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from google.colab import drive\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObcfKZe7XIU9"
      },
      "source": [
        "# Carga de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0f_N9IB-XJka"
      },
      "source": [
        "## Directorio con los datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5X9-nX5XLG8",
        "outputId": "1949f086-ddf6-4618-b577-a7a1b2cea24d"
      },
      "source": [
        "drive.mount('/gdrive')\n",
        "\n",
        "path = \"../gdrive/MyDrive/Data\"\n"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oj2B7fjTXNAU"
      },
      "source": [
        "## Separaci√≥n de los datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9JKOqOUgXGe7",
        "outputId": "7a4fc42c-f4d4-4083-89e6-f7142105b207"
      },
      "source": [
        "data_gen=tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255.,validation_split=0.2)\n",
        "image_datagen=data_gen.flow_from_directory(path,target_size=(300,300),batch_size=32,class_mode='categorical')"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1500 images belonging to 5 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-HHZdlCYFjF",
        "outputId": "0cc71129-24e3-4561-ba6f-33e46107529c"
      },
      "source": [
        "data = []\n",
        "labels = []\n",
        "genres = [\"Cumbia\",\"Vallenato\",\"Salsa\",\"Merengue\",\"Bachata\"]\n",
        "for i in range(len(genres)):   \n",
        "    genre=genres[i]\n",
        "    for img in os.listdir(path+\"/\"+genre):\n",
        "      image=tf.keras.preprocessing.image.load_img(path+\"/\"+genre+\"/\"+img, color_mode='rgb', target_size= (300,300))\n",
        "      image=np.array(image)\n",
        "      data.append(image)\n",
        "      labels.append(i)\n",
        "\n",
        "data = np.array(data)\n",
        "labels = np.array(labels)\n",
        "labels = to_categorical(labels, 5)\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
        "X_train[:2]"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              "\n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              "\n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              "\n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              "\n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]]],\n",
              "\n",
              "\n",
              "       [[[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              "\n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              "\n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              "\n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              "\n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]]]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMmnU_PvdBYm",
        "outputId": "d0998672-5a88-4a7a-9c52-98036124f5e0"
      },
      "source": [
        "y_train[:2]"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99IBI63Cc7Mh"
      },
      "source": [
        "#X_train = np.expand_dims(X_train,axis=3)\n",
        "#X_test = np.expand_dims(X_test,axis=3)\n",
        "\n",
        "# Create an ImageDataGenerator and do Image Augmentation\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255.)\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale = 1./255.)\n",
        "\n",
        "train_generator = train_datagen.flow(X_train, y_train,\n",
        "  batch_size=8\n",
        ")\n",
        "\n",
        "validation_generator = validation_datagen.flow(X_test,y_test,\n",
        "  batch_size=8\n",
        ")\n"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lU2J-Otatta"
      },
      "source": [
        "# Modelo\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPzqJ4FrcSEt"
      },
      "source": [
        "## Carga del modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJAr1ojYauqx"
      },
      "source": [
        "model=VGG16(include_top=False,input_shape=(300,300,3))"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fir_h3pcUJ4"
      },
      "source": [
        "#Congelamiento de capas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzvZieDCaxQ0"
      },
      "source": [
        "for layer in model.layers:\n",
        "    layer.trainable=False"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeS3FtWIcbw-"
      },
      "source": [
        "## √öltimas capas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZdKZn_kcd4t"
      },
      "source": [
        "output=model.layers[-1].output\n",
        "model_final=tf.keras.layers.Flatten()(output)\n",
        "model_final=tf.keras.layers.Dense(512,activation='relu')(model_final)\n",
        "model_final=tf.keras.layers.Dense(64,activation='relu')(model_final)\n",
        "model_final=tf.keras.layers.Dense(5,activation='softmax')(model_final)"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWK6wMLJci4V"
      },
      "source": [
        "## Modelo final"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QILks2NXckOU"
      },
      "source": [
        "model=tf.keras.models.Model(model.input,model_final)"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pZn_C-wclwM"
      },
      "source": [
        "## Compilaci√≥n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAmxIK1TcnYX"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['acc'])\n",
        "#model.compile(loss = 'sparse_categorical_crossentropy', optimizer='rmsprop', metrics=['acc'])\n"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfZZyUu4cn_T"
      },
      "source": [
        "## Entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUEnuQRLcrR_"
      },
      "source": [
        "history = model.fit_generator(train_generator, epochs=2,validation_data = validation_generator)\n",
        "\n",
        "model.evaluate(X_test, y_test, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGtcHETNq9S-"
      },
      "source": [
        "## Evaluaci√≥n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjRGf0CSq-dc"
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'r', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}